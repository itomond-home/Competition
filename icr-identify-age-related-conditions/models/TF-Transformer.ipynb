{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FT-Transformer の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import rtdl\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../train.csv')\n",
    "df_test = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BQ      557 non-null    float64\n",
      " 14  BR      617 non-null    float64\n",
      " 15  BZ      617 non-null    float64\n",
      " 16  CB      615 non-null    float64\n",
      " 17  CC      614 non-null    float64\n",
      " 18  CD      617 non-null    float64\n",
      " 19  CF      617 non-null    float64\n",
      " 20  CH      617 non-null    float64\n",
      " 21  CL      617 non-null    float64\n",
      " 22  CR      617 non-null    float64\n",
      " 23  CS      617 non-null    float64\n",
      " 24  CU      617 non-null    float64\n",
      " 25  CW      617 non-null    float64\n",
      " 26  DA      617 non-null    float64\n",
      " 27  DE      617 non-null    float64\n",
      " 28  DF      617 non-null    float64\n",
      " 29  DH      617 non-null    float64\n",
      " 30  DI      617 non-null    float64\n",
      " 31  DL      617 non-null    float64\n",
      " 32  DN      617 non-null    float64\n",
      " 33  DU      616 non-null    float64\n",
      " 34  DV      617 non-null    float64\n",
      " 35  DY      617 non-null    float64\n",
      " 36  EB      617 non-null    float64\n",
      " 37  EE      617 non-null    float64\n",
      " 38  EG      617 non-null    float64\n",
      " 39  EH      617 non-null    float64\n",
      " 40  EJ      617 non-null    object \n",
      " 41  EL      557 non-null    float64\n",
      " 42  EP      617 non-null    float64\n",
      " 43  EU      617 non-null    float64\n",
      " 44  FC      616 non-null    float64\n",
      " 45  FD      617 non-null    float64\n",
      " 46  FE      617 non-null    float64\n",
      " 47  FI      617 non-null    float64\n",
      " 48  FL      616 non-null    float64\n",
      " 49  FR      617 non-null    float64\n",
      " 50  FS      615 non-null    float64\n",
      " 51  GB      617 non-null    float64\n",
      " 52  GE      617 non-null    float64\n",
      " 53  GF      617 non-null    float64\n",
      " 54  GH      617 non-null    float64\n",
      " 55  GI      617 non-null    float64\n",
      " 56  GL      616 non-null    float64\n",
      " 57  Class   617 non-null    int64  \n",
      "dtypes: float64(55), int64(1), object(2)\n",
      "memory usage: 279.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "seed = 112\n",
    "zero.improve_reproducibility(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_train.fillna(0)\n",
    "task_type = \"binclass\"\n",
    "catfeatures = [\"EJ\"]\n",
    "numfeatures = dataset.drop([\"Id\",\"Class\"]+catfeatures, axis=1).columns.tolist()\n",
    "X_all = dataset[numfeatures].astype(\"double\")\n",
    "y_all = dataset[\"Class\"].astype(\"int64\")\n",
    "y_all = sklearn.preprocessing.LabelEncoder().fit_transform(y_all).astype(\"int64\")\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "X[\"train\"], X[\"test\"], y[\"train\"], y[\"test\"] = sklearn.model_selection.train_test_split(\n",
    "    dataset.drop([\"Id\", \"Class\"], axis=1), dataset[\"Class\"], train_size=0.8, random_state=seed, stratify=dataset[\"Class\"]\n",
    ")\n",
    "X[\"train\"], X[\"val\"], y[\"train\"], y[\"val\"] = sklearn.model_selection.train_test_split(\n",
    "    X[\"train\"], y[\"train\"], train_size=0.8, random_state=seed, stratify=y[\"train\"]\n",
    ")\n",
    "n_features = dataset.drop([\"Class\"], axis=1).shape[1]\n",
    "\n",
    "#Calculate cardinalities as number of unique category values for each categorical features\n",
    "cardinalities = [df_train.iloc[:,0].nunique(), df_train.iloc[:,1].nunique(), df_train.iloc[:,2].nunique(), df_train.iloc[:,3].nunique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not the best way to preprocess features, but for the demonstration purpose\n",
    "def PreprocessNumFeatures(X, y, numfeatures):\n",
    "    \"normalize features\"\n",
    "    preprocess = sklearn.preprocessing.StandardScaler().fit(X[\"train\"][numfeatures])\n",
    "    X = {\n",
    "        k: torch.tensor(preprocess.fit_transform(v[numfeatures]))\n",
    "        for k, v in X.items()\n",
    "    }\n",
    "    y = {k: torch.tensor(v.tolist()) for k, v in y.items()}\n",
    "    y_mean = y[\"train\"].float().mean().item()\n",
    "    y_std = y[\"train\"].float().std().item()\n",
    "    y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
    "    y = {k: v.float() for k, v in y.items()}\n",
    "    return X, y, y_mean, y_std, preprocess\n",
    "\n",
    "def PreprocessCatFeatures(X, catfeatures):\n",
    "    \"Convert categorical(string format) to numerical category\"\n",
    "    preprocess = sklearn.preprocessing.OrdinalEncoder().fit(X[\"train\"][catfeatures])\n",
    "    X = {\n",
    "        k: torch.tensor(preprocess.fit_transform(v[catfeatures])).to(torch.int64)\n",
    "        for k, v in X.items()\n",
    "    }\n",
    "    return X, preprocess\n",
    "\n",
    "X_num, y,y_mean, y_std, scale = PreprocessNumFeatures(X, y, numfeatures)\n",
    "X_cat, ordinal = PreprocessCatFeatures(X, catfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df, scale, ordinal, numfeatures, catfeatures):\n",
    "    X_cat = torch.from_numpy(ordinal.fit_transform(df[catfeatures]))\n",
    "    X_num = torch.from_numpy(scale.fit_transform(df[numfeatures]))\n",
    "\n",
    "    return X_cat,X_num\n",
    "\n",
    "test_cat, test_num = preprocess_test(df_test.drop([\"Id\"], axis=1),scale, ordinal, numfeatures, catfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rtdl.FTTransformer.make_default(\n",
    "    n_num_features=X_num[\"train\"].shape[1],\n",
    "    cat_cardinalities=cardinalities,\n",
    "    last_layer_query_idx=[-1],  # it makes the model faster and does NOT affect its output\n",
    "    d_out=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters())\n",
    ")\n",
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(x_num, x_cat=None):\n",
    "    if isinstance(model, rtdl.FTTransformer):\n",
    "        return model(x_num.float(), x_cat)\n",
    "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
    "        assert x_cat is None\n",
    "        return model(x_num)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'Looks like you are using a custom model: {type(model)}.'\n",
    "            ' Then you have to implement this branch first.'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score before training: 0.1774\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in zero.iter_batches(torch.cat((X_num[part],X_cat[part]), 1) ,1024):\n",
    "        prediction.append(apply_model(batch[:,:55], batch[:, -1:].to(torch.int64)))\n",
    "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
    "    target = y[part].cpu().numpy()\n",
    "    prediction = np.round(scipy.special.expit(prediction))\n",
    "\n",
    "    # Reverse the normalization of the target labels\n",
    "    target = (target * y_std) + y_mean\n",
    "    target = np.round(target)\n",
    "\n",
    "    score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    return score\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = zero.data.IndexLoader(len(X[\"train\"]), batch_size, device=device)\n",
    "\n",
    "progress = zero.ProgressTracker(patience=100)\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 1 (batch) 0 (loss) -141.4786\n",
      "(epoch) 1 (batch) 1 (loss) -74.6255\n",
      "(epoch) 1 (batch) 2 (loss) -121.8938\n",
      "(epoch) 1 (batch) 3 (loss) -122.0004\n",
      "(epoch) 1 (batch) 4 (loss) -71.0981\n",
      "(epoch) 1 (batch) 5 (loss) -115.0926\n",
      "(epoch) 1 (batch) 6 (loss) 1.5214\n",
      "Epoch 001 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 2 (batch) 0 (loss) -147.3284\n",
      "(epoch) 2 (batch) 1 (loss) -77.9790\n",
      "(epoch) 2 (batch) 2 (loss) -119.1450\n",
      "(epoch) 2 (batch) 3 (loss) -119.7935\n",
      "(epoch) 2 (batch) 4 (loss) -74.1565\n",
      "(epoch) 2 (batch) 5 (loss) -123.9295\n",
      "(epoch) 2 (batch) 6 (loss) -0.5170\n",
      "Epoch 002 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 3 (batch) 0 (loss) -143.4414\n",
      "(epoch) 3 (batch) 1 (loss) -89.9877\n",
      "(epoch) 3 (batch) 2 (loss) -123.9265\n",
      "(epoch) 3 (batch) 3 (loss) -116.0043\n",
      "(epoch) 3 (batch) 4 (loss) -65.7333\n",
      "(epoch) 3 (batch) 5 (loss) -117.1241\n",
      "(epoch) 3 (batch) 6 (loss) 1.7708\n",
      "Epoch 003 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 4 (batch) 0 (loss) -144.4074\n",
      "(epoch) 4 (batch) 1 (loss) -88.9027\n",
      "(epoch) 4 (batch) 2 (loss) -124.1545\n",
      "(epoch) 4 (batch) 3 (loss) -113.0591\n",
      "(epoch) 4 (batch) 4 (loss) -73.5951\n",
      "(epoch) 4 (batch) 5 (loss) -122.5266\n",
      "(epoch) 4 (batch) 6 (loss) 1.0602\n",
      "Epoch 004 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 5 (batch) 0 (loss) -148.6770\n",
      "(epoch) 5 (batch) 1 (loss) -83.9230\n",
      "(epoch) 5 (batch) 2 (loss) -126.4254\n",
      "(epoch) 5 (batch) 3 (loss) -117.0690\n",
      "(epoch) 5 (batch) 4 (loss) -69.6867\n",
      "(epoch) 5 (batch) 5 (loss) -114.0241\n",
      "(epoch) 5 (batch) 6 (loss) 2.9087\n",
      "Epoch 005 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 6 (batch) 0 (loss) -149.9824\n",
      "(epoch) 6 (batch) 1 (loss) -73.8166\n",
      "(epoch) 6 (batch) 2 (loss) -123.4794\n",
      "(epoch) 6 (batch) 3 (loss) -117.6993\n",
      "(epoch) 6 (batch) 4 (loss) -77.1034\n",
      "(epoch) 6 (batch) 5 (loss) -117.7102\n",
      "(epoch) 6 (batch) 6 (loss) 2.2454\n",
      "Epoch 006 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 7 (batch) 0 (loss) -142.0700\n",
      "(epoch) 7 (batch) 1 (loss) -81.9970\n",
      "(epoch) 7 (batch) 2 (loss) -121.5690\n",
      "(epoch) 7 (batch) 3 (loss) -117.6903\n",
      "(epoch) 7 (batch) 4 (loss) -70.7518\n",
      "(epoch) 7 (batch) 5 (loss) -114.4772\n",
      "(epoch) 7 (batch) 6 (loss) 0.7233\n",
      "Epoch 007 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 8 (batch) 0 (loss) -145.0363\n",
      "(epoch) 8 (batch) 1 (loss) -77.0042\n",
      "(epoch) 8 (batch) 2 (loss) -125.7581\n",
      "(epoch) 8 (batch) 3 (loss) -109.0210\n",
      "(epoch) 8 (batch) 4 (loss) -79.1720\n",
      "(epoch) 8 (batch) 5 (loss) -117.0483\n",
      "(epoch) 8 (batch) 6 (loss) -0.7271\n",
      "Epoch 008 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 9 (batch) 0 (loss) -141.0427\n",
      "(epoch) 9 (batch) 1 (loss) -75.6786\n",
      "(epoch) 9 (batch) 2 (loss) -122.5184\n",
      "(epoch) 9 (batch) 3 (loss) -117.5056\n",
      "(epoch) 9 (batch) 4 (loss) -74.9040\n",
      "(epoch) 9 (batch) 5 (loss) -115.4290\n",
      "(epoch) 9 (batch) 6 (loss) -1.0839\n",
      "Epoch 009 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 10 (batch) 0 (loss) -145.3535\n",
      "(epoch) 10 (batch) 1 (loss) -80.5332\n",
      "(epoch) 10 (batch) 2 (loss) -120.5206\n",
      "(epoch) 10 (batch) 3 (loss) -115.9084\n",
      "(epoch) 10 (batch) 4 (loss) -76.9789\n",
      "(epoch) 10 (batch) 5 (loss) -115.9914\n",
      "(epoch) 10 (batch) 6 (loss) 1.2884\n",
      "Epoch 010 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 11 (batch) 0 (loss) -142.2898\n",
      "(epoch) 11 (batch) 1 (loss) -78.4347\n",
      "(epoch) 11 (batch) 2 (loss) -126.8237\n",
      "(epoch) 11 (batch) 3 (loss) -123.2629\n",
      "(epoch) 11 (batch) 4 (loss) -74.7089\n",
      "(epoch) 11 (batch) 5 (loss) -113.1310\n",
      "(epoch) 11 (batch) 6 (loss) 2.2938\n",
      "Epoch 011 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 12 (batch) 0 (loss) -145.9644\n",
      "(epoch) 12 (batch) 1 (loss) -80.4486\n",
      "(epoch) 12 (batch) 2 (loss) -124.6582\n",
      "(epoch) 12 (batch) 3 (loss) -112.7430\n",
      "(epoch) 12 (batch) 4 (loss) -65.0055\n",
      "(epoch) 12 (batch) 5 (loss) -114.9693\n",
      "(epoch) 12 (batch) 6 (loss) 0.2025\n",
      "Epoch 012 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 13 (batch) 0 (loss) -142.4176\n",
      "(epoch) 13 (batch) 1 (loss) -78.7543\n",
      "(epoch) 13 (batch) 2 (loss) -125.7360\n",
      "(epoch) 13 (batch) 3 (loss) -113.0144\n",
      "(epoch) 13 (batch) 4 (loss) -75.5626\n",
      "(epoch) 13 (batch) 5 (loss) -123.5330\n",
      "(epoch) 13 (batch) 6 (loss) 5.1381\n",
      "Epoch 013 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 14 (batch) 0 (loss) -141.0746\n",
      "(epoch) 14 (batch) 1 (loss) -78.5064\n",
      "(epoch) 14 (batch) 2 (loss) -128.5632\n",
      "(epoch) 14 (batch) 3 (loss) -116.8984\n",
      "(epoch) 14 (batch) 4 (loss) -76.4231\n",
      "(epoch) 14 (batch) 5 (loss) -118.9172\n",
      "(epoch) 14 (batch) 6 (loss) 2.0767\n",
      "Epoch 014 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 15 (batch) 0 (loss) -142.0571\n",
      "(epoch) 15 (batch) 1 (loss) -81.1205\n",
      "(epoch) 15 (batch) 2 (loss) -129.0952\n",
      "(epoch) 15 (batch) 3 (loss) -119.0647\n",
      "(epoch) 15 (batch) 4 (loss) -82.6471\n",
      "(epoch) 15 (batch) 5 (loss) -117.3517\n",
      "(epoch) 15 (batch) 6 (loss) 0.5679\n",
      "Epoch 015 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 16 (batch) 0 (loss) -140.0266\n",
      "(epoch) 16 (batch) 1 (loss) -72.9079\n",
      "(epoch) 16 (batch) 2 (loss) -128.8020\n",
      "(epoch) 16 (batch) 3 (loss) -112.3626\n",
      "(epoch) 16 (batch) 4 (loss) -68.9711\n",
      "(epoch) 16 (batch) 5 (loss) -117.9149\n",
      "(epoch) 16 (batch) 6 (loss) -1.1277\n",
      "Epoch 016 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 17 (batch) 0 (loss) -144.4429\n",
      "(epoch) 17 (batch) 1 (loss) -77.3495\n",
      "(epoch) 17 (batch) 2 (loss) -129.4939\n",
      "(epoch) 17 (batch) 3 (loss) -116.4982\n",
      "(epoch) 17 (batch) 4 (loss) -78.2872\n",
      "(epoch) 17 (batch) 5 (loss) -120.4909\n",
      "(epoch) 17 (batch) 6 (loss) 1.4470\n",
      "Epoch 017 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 18 (batch) 0 (loss) -143.0995\n",
      "(epoch) 18 (batch) 1 (loss) -75.0309\n",
      "(epoch) 18 (batch) 2 (loss) -119.4559\n",
      "(epoch) 18 (batch) 3 (loss) -114.1765\n",
      "(epoch) 18 (batch) 4 (loss) -66.4940\n",
      "(epoch) 18 (batch) 5 (loss) -117.2970\n",
      "(epoch) 18 (batch) 6 (loss) -0.2883\n",
      "Epoch 018 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 19 (batch) 0 (loss) -146.3988\n",
      "(epoch) 19 (batch) 1 (loss) -79.9939\n",
      "(epoch) 19 (batch) 2 (loss) -127.0807\n",
      "(epoch) 19 (batch) 3 (loss) -118.1105\n",
      "(epoch) 19 (batch) 4 (loss) -75.5228\n",
      "(epoch) 19 (batch) 5 (loss) -121.0490\n",
      "(epoch) 19 (batch) 6 (loss) -1.7727\n",
      "Epoch 019 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 20 (batch) 0 (loss) -144.1474\n",
      "(epoch) 20 (batch) 1 (loss) -79.2042\n",
      "(epoch) 20 (batch) 2 (loss) -128.8909\n",
      "(epoch) 20 (batch) 3 (loss) -118.7149\n",
      "(epoch) 20 (batch) 4 (loss) -66.4540\n",
      "(epoch) 20 (batch) 5 (loss) -116.1379\n",
      "(epoch) 20 (batch) 6 (loss) -1.0924\n",
      "Epoch 020 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 21 (batch) 0 (loss) -149.9294\n",
      "(epoch) 21 (batch) 1 (loss) -73.5740\n",
      "(epoch) 21 (batch) 2 (loss) -127.1005\n",
      "(epoch) 21 (batch) 3 (loss) -118.0946\n",
      "(epoch) 21 (batch) 4 (loss) -69.1457\n",
      "(epoch) 21 (batch) 5 (loss) -118.5398\n",
      "(epoch) 21 (batch) 6 (loss) -0.5442\n",
      "Epoch 021 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 22 (batch) 0 (loss) -146.6559\n",
      "(epoch) 22 (batch) 1 (loss) -81.1032\n",
      "(epoch) 22 (batch) 2 (loss) -124.8041\n",
      "(epoch) 22 (batch) 3 (loss) -127.0703\n",
      "(epoch) 22 (batch) 4 (loss) -79.0028\n",
      "(epoch) 22 (batch) 5 (loss) -120.6818\n",
      "(epoch) 22 (batch) 6 (loss) -1.6093\n",
      "Epoch 022 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 23 (batch) 0 (loss) -144.0073\n",
      "(epoch) 23 (batch) 1 (loss) -75.4909\n",
      "(epoch) 23 (batch) 2 (loss) -123.8396\n",
      "(epoch) 23 (batch) 3 (loss) -121.3156\n",
      "(epoch) 23 (batch) 4 (loss) -72.8770\n",
      "(epoch) 23 (batch) 5 (loss) -119.3688\n",
      "(epoch) 23 (batch) 6 (loss) 4.9953\n",
      "Epoch 023 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 24 (batch) 0 (loss) -146.5994\n",
      "(epoch) 24 (batch) 1 (loss) -77.7040\n",
      "(epoch) 24 (batch) 2 (loss) -123.6220\n",
      "(epoch) 24 (batch) 3 (loss) -116.1083\n",
      "(epoch) 24 (batch) 4 (loss) -73.1284\n",
      "(epoch) 24 (batch) 5 (loss) -118.2703\n",
      "(epoch) 24 (batch) 6 (loss) 2.9063\n",
      "Epoch 024 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 25 (batch) 0 (loss) -139.0876\n",
      "(epoch) 25 (batch) 1 (loss) -74.0955\n",
      "(epoch) 25 (batch) 2 (loss) -127.2660\n",
      "(epoch) 25 (batch) 3 (loss) -118.4754\n",
      "(epoch) 25 (batch) 4 (loss) -68.6227\n",
      "(epoch) 25 (batch) 5 (loss) -117.3785\n",
      "(epoch) 25 (batch) 6 (loss) -0.4154\n",
      "Epoch 025 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 26 (batch) 0 (loss) -148.0846\n",
      "(epoch) 26 (batch) 1 (loss) -78.2792\n",
      "(epoch) 26 (batch) 2 (loss) -122.5470\n",
      "(epoch) 26 (batch) 3 (loss) -115.6794\n",
      "(epoch) 26 (batch) 4 (loss) -74.3786\n",
      "(epoch) 26 (batch) 5 (loss) -118.2500\n",
      "(epoch) 26 (batch) 6 (loss) 5.5181\n",
      "Epoch 026 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 27 (batch) 0 (loss) -144.4349\n",
      "(epoch) 27 (batch) 1 (loss) -80.8843\n",
      "(epoch) 27 (batch) 2 (loss) -125.6114\n",
      "(epoch) 27 (batch) 3 (loss) -117.8663\n",
      "(epoch) 27 (batch) 4 (loss) -72.2571\n",
      "(epoch) 27 (batch) 5 (loss) -106.6012\n",
      "(epoch) 27 (batch) 6 (loss) 2.0489\n",
      "Epoch 027 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 28 (batch) 0 (loss) -143.8097\n",
      "(epoch) 28 (batch) 1 (loss) -68.0595\n",
      "(epoch) 28 (batch) 2 (loss) -119.6437\n",
      "(epoch) 28 (batch) 3 (loss) -119.5326\n",
      "(epoch) 28 (batch) 4 (loss) -71.2004\n",
      "(epoch) 28 (batch) 5 (loss) -118.0763\n",
      "(epoch) 28 (batch) 6 (loss) 4.7260\n",
      "Epoch 028 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 29 (batch) 0 (loss) -143.5895\n",
      "(epoch) 29 (batch) 1 (loss) -77.4561\n",
      "(epoch) 29 (batch) 2 (loss) -125.1352\n",
      "(epoch) 29 (batch) 3 (loss) -122.3079\n",
      "(epoch) 29 (batch) 4 (loss) -71.8208\n",
      "(epoch) 29 (batch) 5 (loss) -111.6445\n",
      "(epoch) 29 (batch) 6 (loss) -0.9544\n",
      "Epoch 029 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 30 (batch) 0 (loss) -142.8281\n",
      "(epoch) 30 (batch) 1 (loss) -85.4381\n",
      "(epoch) 30 (batch) 2 (loss) -122.0561\n",
      "(epoch) 30 (batch) 3 (loss) -122.8382\n",
      "(epoch) 30 (batch) 4 (loss) -74.4548\n",
      "(epoch) 30 (batch) 5 (loss) -119.6035\n",
      "(epoch) 30 (batch) 6 (loss) 1.2942\n",
      "Epoch 030 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 31 (batch) 0 (loss) -146.7271\n",
      "(epoch) 31 (batch) 1 (loss) -88.8087\n",
      "(epoch) 31 (batch) 2 (loss) -128.0284\n",
      "(epoch) 31 (batch) 3 (loss) -111.5556\n",
      "(epoch) 31 (batch) 4 (loss) -83.5836\n",
      "(epoch) 31 (batch) 5 (loss) -116.0418\n",
      "(epoch) 31 (batch) 6 (loss) 1.1733\n",
      "Epoch 031 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 32 (batch) 0 (loss) -141.4822\n",
      "(epoch) 32 (batch) 1 (loss) -78.5520\n",
      "(epoch) 32 (batch) 2 (loss) -121.6939\n",
      "(epoch) 32 (batch) 3 (loss) -118.6816\n",
      "(epoch) 32 (batch) 4 (loss) -64.9921\n",
      "(epoch) 32 (batch) 5 (loss) -122.2092\n",
      "(epoch) 32 (batch) 6 (loss) 0.8594\n",
      "Epoch 032 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 33 (batch) 0 (loss) -149.9258\n",
      "(epoch) 33 (batch) 1 (loss) -83.6369\n",
      "(epoch) 33 (batch) 2 (loss) -124.5382\n",
      "(epoch) 33 (batch) 3 (loss) -114.5297\n",
      "(epoch) 33 (batch) 4 (loss) -75.4596\n",
      "(epoch) 33 (batch) 5 (loss) -119.3787\n",
      "(epoch) 33 (batch) 6 (loss) 0.0156\n",
      "Epoch 033 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 34 (batch) 0 (loss) -138.2627\n",
      "(epoch) 34 (batch) 1 (loss) -81.5228\n",
      "(epoch) 34 (batch) 2 (loss) -125.7283\n",
      "(epoch) 34 (batch) 3 (loss) -115.4662\n",
      "(epoch) 34 (batch) 4 (loss) -68.7977\n",
      "(epoch) 34 (batch) 5 (loss) -115.0786\n",
      "(epoch) 34 (batch) 6 (loss) 0.2458\n",
      "Epoch 034 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 35 (batch) 0 (loss) -143.1140\n",
      "(epoch) 35 (batch) 1 (loss) -81.2630\n",
      "(epoch) 35 (batch) 2 (loss) -125.7406\n",
      "(epoch) 35 (batch) 3 (loss) -107.9291\n",
      "(epoch) 35 (batch) 4 (loss) -75.8275\n",
      "(epoch) 35 (batch) 5 (loss) -116.2559\n",
      "(epoch) 35 (batch) 6 (loss) -0.4233\n",
      "Epoch 035 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 36 (batch) 0 (loss) -145.5116\n",
      "(epoch) 36 (batch) 1 (loss) -72.2258\n",
      "(epoch) 36 (batch) 2 (loss) -121.9694\n",
      "(epoch) 36 (batch) 3 (loss) -120.4208\n",
      "(epoch) 36 (batch) 4 (loss) -75.6419\n",
      "(epoch) 36 (batch) 5 (loss) -114.6543\n",
      "(epoch) 36 (batch) 6 (loss) 1.5478\n",
      "Epoch 036 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 37 (batch) 0 (loss) -140.1403\n",
      "(epoch) 37 (batch) 1 (loss) -84.8998\n",
      "(epoch) 37 (batch) 2 (loss) -128.6452\n",
      "(epoch) 37 (batch) 3 (loss) -114.1825\n",
      "(epoch) 37 (batch) 4 (loss) -78.0529\n",
      "(epoch) 37 (batch) 5 (loss) -120.1187\n",
      "(epoch) 37 (batch) 6 (loss) 2.4207\n",
      "Epoch 037 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 38 (batch) 0 (loss) -140.3565\n",
      "(epoch) 38 (batch) 1 (loss) -77.2702\n",
      "(epoch) 38 (batch) 2 (loss) -124.2474\n",
      "(epoch) 38 (batch) 3 (loss) -122.2344\n",
      "(epoch) 38 (batch) 4 (loss) -76.2095\n",
      "(epoch) 38 (batch) 5 (loss) -115.6904\n",
      "(epoch) 38 (batch) 6 (loss) -0.0667\n",
      "Epoch 038 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 39 (batch) 0 (loss) -147.4664\n",
      "(epoch) 39 (batch) 1 (loss) -67.4936\n",
      "(epoch) 39 (batch) 2 (loss) -126.5177\n",
      "(epoch) 39 (batch) 3 (loss) -118.4980\n",
      "(epoch) 39 (batch) 4 (loss) -76.6065\n",
      "(epoch) 39 (batch) 5 (loss) -113.7633\n",
      "(epoch) 39 (batch) 6 (loss) 0.8474\n",
      "Epoch 039 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 40 (batch) 0 (loss) -146.0616\n",
      "(epoch) 40 (batch) 1 (loss) -85.4211\n",
      "(epoch) 40 (batch) 2 (loss) -123.6528\n",
      "(epoch) 40 (batch) 3 (loss) -118.4226\n",
      "(epoch) 40 (batch) 4 (loss) -68.2497\n",
      "(epoch) 40 (batch) 5 (loss) -119.4397\n",
      "(epoch) 40 (batch) 6 (loss) -0.0630\n",
      "Epoch 040 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 41 (batch) 0 (loss) -134.9961\n",
      "(epoch) 41 (batch) 1 (loss) -75.3981\n",
      "(epoch) 41 (batch) 2 (loss) -124.5229\n",
      "(epoch) 41 (batch) 3 (loss) -112.5295\n",
      "(epoch) 41 (batch) 4 (loss) -74.9402\n",
      "(epoch) 41 (batch) 5 (loss) -117.7718\n",
      "(epoch) 41 (batch) 6 (loss) 3.8453\n",
      "Epoch 041 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 42 (batch) 0 (loss) -150.9560\n",
      "(epoch) 42 (batch) 1 (loss) -83.0277\n",
      "(epoch) 42 (batch) 2 (loss) -125.1517\n",
      "(epoch) 42 (batch) 3 (loss) -118.1539\n",
      "(epoch) 42 (batch) 4 (loss) -80.2126\n",
      "(epoch) 42 (batch) 5 (loss) -122.6620\n",
      "(epoch) 42 (batch) 6 (loss) 1.3161\n",
      "Epoch 042 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 43 (batch) 0 (loss) -146.7212\n",
      "(epoch) 43 (batch) 1 (loss) -87.5733\n",
      "(epoch) 43 (batch) 2 (loss) -127.1146\n",
      "(epoch) 43 (batch) 3 (loss) -114.1478\n",
      "(epoch) 43 (batch) 4 (loss) -71.5709\n",
      "(epoch) 43 (batch) 5 (loss) -119.8539\n",
      "(epoch) 43 (batch) 6 (loss) 1.8714\n",
      "Epoch 043 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 44 (batch) 0 (loss) -146.0176\n",
      "(epoch) 44 (batch) 1 (loss) -74.7350\n",
      "(epoch) 44 (batch) 2 (loss) -124.8316\n",
      "(epoch) 44 (batch) 3 (loss) -113.5740\n",
      "(epoch) 44 (batch) 4 (loss) -74.8920\n",
      "(epoch) 44 (batch) 5 (loss) -112.8665\n",
      "(epoch) 44 (batch) 6 (loss) 0.7280\n",
      "Epoch 044 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 45 (batch) 0 (loss) -148.5937\n",
      "(epoch) 45 (batch) 1 (loss) -85.1034\n",
      "(epoch) 45 (batch) 2 (loss) -123.5281\n",
      "(epoch) 45 (batch) 3 (loss) -113.9214\n",
      "(epoch) 45 (batch) 4 (loss) -75.1127\n",
      "(epoch) 45 (batch) 5 (loss) -114.6366\n",
      "(epoch) 45 (batch) 6 (loss) -0.1485\n",
      "Epoch 045 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 46 (batch) 0 (loss) -146.4102\n",
      "(epoch) 46 (batch) 1 (loss) -71.8384\n",
      "(epoch) 46 (batch) 2 (loss) -127.9100\n",
      "(epoch) 46 (batch) 3 (loss) -115.8513\n",
      "(epoch) 46 (batch) 4 (loss) -76.2630\n",
      "(epoch) 46 (batch) 5 (loss) -114.8264\n",
      "(epoch) 46 (batch) 6 (loss) 1.1447\n",
      "Epoch 046 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 47 (batch) 0 (loss) -144.4221\n",
      "(epoch) 47 (batch) 1 (loss) -73.6602\n",
      "(epoch) 47 (batch) 2 (loss) -123.4762\n",
      "(epoch) 47 (batch) 3 (loss) -120.8480\n",
      "(epoch) 47 (batch) 4 (loss) -86.7607\n",
      "(epoch) 47 (batch) 5 (loss) -122.5938\n",
      "(epoch) 47 (batch) 6 (loss) 4.8427\n",
      "Epoch 047 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 48 (batch) 0 (loss) -140.8977\n",
      "(epoch) 48 (batch) 1 (loss) -83.6421\n",
      "(epoch) 48 (batch) 2 (loss) -123.7616\n",
      "(epoch) 48 (batch) 3 (loss) -115.2341\n",
      "(epoch) 48 (batch) 4 (loss) -77.2581\n",
      "(epoch) 48 (batch) 5 (loss) -116.6243\n",
      "(epoch) 48 (batch) 6 (loss) 1.3385\n",
      "Epoch 048 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 49 (batch) 0 (loss) -143.6855\n",
      "(epoch) 49 (batch) 1 (loss) -72.7583\n",
      "(epoch) 49 (batch) 2 (loss) -122.8741\n",
      "(epoch) 49 (batch) 3 (loss) -109.2796\n",
      "(epoch) 49 (batch) 4 (loss) -70.9495\n",
      "(epoch) 49 (batch) 5 (loss) -121.5904\n",
      "(epoch) 49 (batch) 6 (loss) 5.2451\n",
      "Epoch 049 | Validation score: 0.9192 | Test score: 0.9032\n",
      "(epoch) 50 (batch) 0 (loss) -142.8965\n",
      "(epoch) 50 (batch) 1 (loss) -78.4188\n",
      "(epoch) 50 (batch) 2 (loss) -128.4415\n",
      "(epoch) 50 (batch) 3 (loss) -115.9331\n",
      "(epoch) 50 (batch) 4 (loss) -72.9079\n",
      "(epoch) 50 (batch) 5 (loss) -116.6829\n",
      "(epoch) 50 (batch) 6 (loss) 2.9044\n",
      "Epoch 050 | Validation score: 0.9192 | Test score: 0.9032\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50 # can increase the epoch size\n",
    "report_frequency = len(X['train']) // batch_size // 5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_num_batch = X_num['train'][batch_idx]\n",
    "        x_cat_batch = X_cat['train'][batch_idx].to(torch.int64)\n",
    "        y_batch = y['train'][batch_idx]\n",
    "        loss = loss_fn(apply_model(x_num_batch, x_cat_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % report_frequency == 0:\n",
    "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    print('using device: cuda')\n",
    "else:\n",
    "    print('using device: cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU and torch.cuda.is_available():\n",
    "    test_num = test_num.float().cuda()\n",
    "    test_cat = test_cat.to(torch.int64).cuda()\n",
    "    dtype1 = torch.cuda.FloatTensor\n",
    "    dtype2 = torch.cuda.IntTensor\n",
    "    model.cuda()\n",
    "else:\n",
    "    test_num = test_num.float()\n",
    "    test_cat = test_cat.to(torch.int64)\n",
    "    dtype1 = torch.FloatTensor\n",
    "    dtype2 = torch.IntTensor  # Change this line\n",
    "\n",
    "test_num = Variable(test_num).type(dtype1)\n",
    "test_cat = Variable(test_cat).type(dtype2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(test_num, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame()\n",
    "Submission[\"Id\"] = df_test[\"Id\"]\n",
    "Submission[\"Class\"] = (predict.cpu().detach().numpy() * y_std) + y_mean\n",
    "Submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
