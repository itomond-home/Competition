{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FT-Transformer の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import rtdl\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../train.csv')\n",
    "df_test = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "seed = 112\n",
    "zero.improve_reproducibility(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_train.fillna(0)\n",
    "task_type = \"binclass\"\n",
    "catfeatures = [\"EJ\"]\n",
    "numfeatures = dataset.drop([\"Id\",\"Class\"]+catfeatures, axis=1).columns.tolist()\n",
    "X_all = dataset[numfeatures].astype(\"double\")\n",
    "y_all = dataset[\"Class\"].astype(\"int64\")\n",
    "y_all = sklearn.preprocessing.LabelEncoder().fit_transform(y_all).astype(\"int64\")\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "X[\"train\"], X[\"test\"], y[\"train\"], y[\"test\"] = sklearn.model_selection.train_test_split(\n",
    "    dataset.drop([\"Id\", \"Class\"], axis=1), dataset[\"Class\"], train_size=0.8, random_state=seed, stratify=dataset[\"Class\"]\n",
    ")\n",
    "X[\"train\"], X[\"val\"], y[\"train\"], y[\"val\"] = sklearn.model_selection.train_test_split(\n",
    "    X[\"train\"], y[\"train\"], train_size=0.8, random_state=seed, stratify=y[\"train\"]\n",
    ")\n",
    "n_features = dataset.drop([\"Class\"], axis=1).shape[1]\n",
    "\n",
    "#Calculate cardinalities as number of unique category values for each categorical features\n",
    "cardinalities = [df_train.iloc[:,0].nunique(), df_train.iloc[:,1].nunique(), df_train.iloc[:,2].nunique(), df_train.iloc[:,3].nunique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not the best way to preprocess features, but for the demonstration purpose\n",
    "def PreprocessNumFeatures(X, y, numfeatures):\n",
    "    \"normalize features\"\n",
    "    preprocess = sklearn.preprocessing.StandardScaler().fit(X[\"train\"][numfeatures])\n",
    "    X = {\n",
    "        k: torch.tensor(preprocess.fit_transform(v[numfeatures]))\n",
    "        for k, v in X.items()\n",
    "    }\n",
    "    y = {k: torch.tensor(v.tolist()) for k, v in y.items()}\n",
    "    y_mean = y[\"train\"].float().mean().item()\n",
    "    y_std = y[\"train\"].float().std().item()\n",
    "    y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
    "    y = {k: v.float() for k, v in y.items()}\n",
    "    return X, y, y_mean, y_std, preprocess\n",
    "\n",
    "def PreprocessCatFeatures(X, catfeatures):\n",
    "    \"Convert categorical(string format) to numerical category\"\n",
    "    preprocess = sklearn.preprocessing.OrdinalEncoder().fit(X[\"train\"][catfeatures])\n",
    "    X = {\n",
    "        k: torch.tensor(preprocess.fit_transform(v[catfeatures])).to(torch.int64)\n",
    "        for k, v in X.items()\n",
    "    }\n",
    "    return X, preprocess\n",
    "\n",
    "X_num, y,y_mean, y_std, scale = PreprocessNumFeatures(X, y, numfeatures)\n",
    "X_cat, ordinal = PreprocessCatFeatures(X, catfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df, scale, ordinal, numfeatures, catfeatures):\n",
    "    X_cat = torch.from_numpy(ordinal.fit_transform(df[catfeatures]))\n",
    "    X_num = torch.from_numpy(scale.fit_transform(df[numfeatures]))\n",
    "\n",
    "    return X_cat,X_num\n",
    "\n",
    "test_cat, test_num = preprocess_test(df_test.drop([\"Id\"], axis=1),scale, ordinal, numfeatures, catfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rtdl.FTTransformer.make_default(\n",
    "    n_num_features=X_num[\"train\"].shape[1],\n",
    "    cat_cardinalities=cardinalities,\n",
    "    last_layer_query_idx=[-1],  # it makes the model faster and does NOT affect its output\n",
    "    d_out=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters())\n",
    ")\n",
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(x_num, x_cat=None):\n",
    "    if isinstance(model, rtdl.FTTransformer):\n",
    "        return model(x_num.float(), x_cat)\n",
    "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
    "        assert x_cat is None\n",
    "        return model(x_num)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'Looks like you are using a custom model: {type(model)}.'\n",
    "            ' Then you have to implement this branch first.'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in zero.iter_batches(torch.cat((X_num[part],X_cat[part]), 1) ,1024):\n",
    "        prediction.append(apply_model(batch[:,:55], batch[:, -1:].to(torch.int64)))\n",
    "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
    "    target = y[part].cpu().numpy()\n",
    "    prediction = np.round(scipy.special.expit(prediction))\n",
    "\n",
    "    # Reverse the normalization of the target labels\n",
    "    target = (target * y_std) + y_mean\n",
    "    target = np.round(target)\n",
    "\n",
    "    score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    return score\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = zero.data.IndexLoader(len(X[\"train\"]), batch_size, device=device)\n",
    "\n",
    "progress = zero.ProgressTracker(patience=100)\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50 # can increase the epoch size\n",
    "report_frequency = len(X['train']) // batch_size // 5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_num_batch = X_num['train'][batch_idx]\n",
    "        x_cat_batch = X_cat['train'][batch_idx].to(torch.int64)\n",
    "        y_batch = y['train'][batch_idx]\n",
    "        loss = loss_fn(apply_model(x_num_batch, x_cat_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % report_frequency == 0:\n",
    "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    print('using device: cuda')\n",
    "else:\n",
    "    print('using device: cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU and torch.cuda.is_available():\n",
    "    test_num = test_num.float().cuda()\n",
    "    test_cat = test_cat.to(torch.int64).cuda()\n",
    "    dtype1 = torch.cuda.FloatTensor\n",
    "    dtype2 = torch.cuda.IntTensor\n",
    "    model.cuda()\n",
    "else:\n",
    "    test_num = test_num.float()\n",
    "    test_cat = test_cat.to(torch.int64)\n",
    "    dtype1 = torch.FloatTensor\n",
    "    dtype2 = torch.IntTensor  # Change this line\n",
    "\n",
    "test_num = Variable(test_num).type(dtype1)\n",
    "test_cat = Variable(test_cat).type(dtype2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(test_num, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame()\n",
    "Submission[\"Id\"] = df_test[\"Id\"]\n",
    "Submission[\"Class\"] = (predict.cpu().detach().numpy() * y_std) + y_mean\n",
    "Submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
