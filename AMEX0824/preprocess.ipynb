{"cells":[{"cell_type":"markdown","metadata":{"id":"gkbz2eQviaSo"},"source":["## データセット作成"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xjmk5fcZ-Iwx"},"outputs":[],"source":["# ライブラリのインポート\n","import gc\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ0GI7z43N6s"},"outputs":[],"source":["# データのダウンロード\n","train = pd.read_parquet('')\n","test = pd.read_parquet('')"]},{"cell_type":"markdown","metadata":{"id":"5xWXynruW37X"},"source":["# 関数群\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vhj7fPiRHqxd"},"outputs":[],"source":["def reduce_mem_usage(df):\n","    \"\"\" メモリ削減 する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    # float64 と float32 のデータタイプを float16 に加工\n","    cols1 = list(df.dtypes[df.dtypes == 'float64'].index) + list(df.dtypes[df.dtypes == 'float32'].index) \n","    for col in tqdm(cols1):\n","        df[col] = df[col].astype(np.float16)\n","\n","    # int64, int32, int16 のデータタイプを int8 に加工 \n","    cols2 = list(df.dtypes[df.dtypes == 'int64'].index) + list(df.dtypes[df.dtypes == 'int32'].index)+ list(df.dtypes[df.dtypes == 'int16'].index)\n","    for col in tqdm(cols2):\n","        df[col] = df[col].astype(np.int8)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-Un4LJeHrYO"},"outputs":[],"source":["def get_concat(df, df1):\n","    \"\"\" マージ する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        df1(DataFrame) : 追加するデータベース\n","\n","    Return:\n","        df(DataFrame) : マージしたデータベース\n","\n","    \"\"\"\n","\n","    # マージする\n","    df = pd.concat([\n","        df.reset_index(drop=True),\n","        df1.reindex(df[\"customer_ID\"].values).reset_index(drop=True)\n","    ], axis=1)\n","\n","    # 不要なデータベースの削除\n","    del df1\n","    gc.collect()\n","\n","    print(\"\\n\", f\"Now {len(df.columns.tolist())} features...\")\n","\n","    # 余分なメモリの削除\n","    df = reduce_mem_usage(df)\n","    gc.collect() \n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGriVtVtHsW0"},"outputs":[],"source":["def get_datetime(df):\n","    \"\"\" datetime に関するデータ加工の関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get datetime\", \"#\"*4)\n","    # 処理の開始\n","    df1 = df.drop(df.columns.tolist(), axis=1).copy()\n","    df['S_2'] = pd.to_datetime(df['S_2'])\n","    df1['S_2_year'] = df['S_2'].dt.year\n","    df1['S_2_month'] = df['S_2'].dt.month\n","    df1['S_2_day'] = df['S_2'].dt.day\n","    df1['S_2_day_of_week'] = df['S_2'].dt.day_of_week\n","    df1['S_2_day_of_year'] = df['S_2'].dt.day_of_year\n","    df1['S_2_is_year_start'] = df['S_2'].dt.is_year_start\n","    df1['S_2_is_quarter_start'] = df['S_2'].dt.is_quarter_start\n","    df1['S_2_is_month_start'] = df['S_2'].dt.is_month_start\n","    df1['S_2_is_month_end'] = df['S_2'].dt.is_month_end\n","    df1['S_2_is_weekend'] = np.where(df1['S_2_day_of_week'].isin([5,6]), 1,0)\n","    df1['month_sin'] = np.sin(2 * np.pi * df['S_2'].dt.month/12.0) \n","    df1['month_cos'] = np.cos(2 * np.pi * df['S_2'].dt.month/12.0)\n","    \n","    # 既存データベースにマージする\n","    df = get_concat(df, df1)\n","    \n","    # 日付の変数はもう要らないので削除\n","    df = df.drop(\"S_2\", axis = 1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mz530lLMH0I3"},"outputs":[],"source":["def get_shift(df, num_features, groups):\n","    \"\"\" シフト変数を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get shift\", \"#\"*4)\n","    df1 = []\n","    customer_ids = []\n","    # customer_ID ごとにデータを作成\n","    for customer_id, df in tqdm(groups):\n","        diff_df1 = df[num_features].shift(1).iloc[[-1]].values.astype(np.float32) \n","        df1.append(diff_df1)  \n","        customer_ids.append(customer_id) \n","\n","    # データベースとして作成\n","    df1 = np.concatenate(df1, axis = 0)\n","    df1 = pd.DataFrame(df1, columns = [col + '_shift' for col in df[num_features].columns])\n","    df1['customer_ID'] = customer_ids\n","    \n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcBz6pWsH0ot"},"outputs":[],"source":["def get_diff(df, num_features, groups):\n","    \"\"\" 差分を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get difference\", \"#\"*4)\n","    df1 = []\n","    customer_ids = []\n","    # customer_ID ごとにデータを作成\n","    for customer_id, df in tqdm(groups):\n","        diff_df1 = df[num_features].diff().iloc[[-1]].values.astype(np.float32) \n","        df1.append(diff_df1)  \n","        customer_ids.append(customer_id) \n","\n","    # データベースとして作成\n","    df1 = np.concatenate(df1, axis = 0)\n","    df1 = pd.DataFrame(df1, columns = [col + '_diff' for col in df[num_features].columns])\n","    df1['customer_ID'] = customer_ids\n","    \n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0p7mxnYEH1kV"},"outputs":[],"source":["def get_mean(df, num_features, groups):\n","    \"\"\" 平均を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get mean\", \"#\"*4)\n","    # customer_ID ごとの mean を作成\n","    df1 = groups[num_features].agg(['mean']).copy()\n","    df1.columns = [col + '_mean' for col in num_features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k1VNRq-PH2hh"},"outputs":[],"source":["def get_std(df, num_features, groups):\n","    \"\"\" 標準偏差を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get std\", \"#\"*4)\n","    # customer_ID ごとの std を作成\n","    df1 = groups[num_features].agg(['std']).copy()\n","    df1.columns = [col + '_std' for col in num_features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWP9WhR1H3iX"},"outputs":[],"source":["def get_median(df, num_features, groups):\n","    \"\"\" 中央値を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get median\", \"#\"*4)\n","    # customer_ID ごとの median を作成\n","    df1 = groups[num_features].agg(['median']).copy()\n","    df1.columns = [col + '_median' for col in num_features]\n","    \n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAZ6rH6OH4nO"},"outputs":[],"source":["def get_min(df, num_features, groups):\n","    \"\"\" 最小値を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get min\", \"#\"*4)\n","    # customer_ID ごとの min を作成\n","    df1 = groups[num_features].agg(['min']).copy()\n","    df1.columns = [col + '_min' for col in num_features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","        \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDIouF2HH5nR"},"outputs":[],"source":["def get_max(df, num_features, groups):\n","    \"\"\" 最大値を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get max\", \"#\"*4)\n","    # customer_ID ごとの max を作成\n","    df1 = groups[num_features].agg(['max']).copy()\n","    df1.columns = [col + '_max' for col in num_features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","        \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMVdflRPH6st"},"outputs":[],"source":["def get_var(df, num_features, groups):\n","    \"\"\" 分散を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","    \n","    print(\"\\n\", \"#\"*4, \"get var\", \"#\"*4)\n","    # customer_ID ごとの var を作成\n","    df1 = groups[num_features].agg(['var']).copy()\n","    df1.columns = [col + '_var' for col in num_features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","        \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCZCC0VwH7lL"},"outputs":[],"source":["def get_first(df, features, groups):\n","    \"\"\" 最初の値を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        features(list) : 変数名リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","    \n","    print(\"\\n\", \"#\"*4, \"get first\", \"#\"*4)\n","    # customer_ID ごとの first を作成\n","    df1 = groups[features].agg(['first']).copy()\n","    df1.columns = [col + '_first' for col in features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","            \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TcCP7bGKH8j5"},"outputs":[],"source":["def get_last(df, features, groups):\n","    \"\"\" 最初の値を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        features(list) : 変数名リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get last\", \"#\"*4)\n","    # customer_ID ごとの last を作成\n","    df1 = groups[features].agg(['last']).copy()\n","    df1.columns = [col + '_last' for col in features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TosZQNjSH-B1"},"outputs":[],"source":["def get_count(df, cat_features, groups):\n","    \"\"\" 頻度を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        cat_features(list) : カテゴリ型の変数名リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get count\", \"#\"*4)\n","    # customer_ID ごとの count を作成\n","    df1 = groups[cat_features].agg(['count']).copy()\n","    df1.columns = [col + '_count' for col in cat_features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYnSoD8xH_Np"},"outputs":[],"source":["def get_nunique(df, cat_features, groups):\n","    \"\"\" 種数(一意の値の個数)を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        cat_features(list) : カテゴリ型の変数名リスト\n","        groups(DataFrame) : customer_ID ごとにグループバイしたデータベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get nunique\", \"#\"*4)\n","    # customer_ID ごとの nunique を作成\n","    df1 = groups[cat_features].agg(['nunique']).copy()\n","    df1.columns = [col + '_nunique' for col in cat_features]\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzx6puanIASd"},"outputs":[],"source":["def get_current_level(df, num_features, df_drop):\n","    \"\"\" 現在の水準レベルを追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数名リスト\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get current lebel\", \"#\"*4)\n","    # 各列 ごとの current_level を作成\n","    new_columns = {f'{col}_current_level': (df[f\"{col}_last\"] - df[f\"{col}_min\"]) / (df[f\"{col}_max\"] - df[f\"{col}_min\"]) for col in tqdm(num_features)}\n","    new_df = pd.DataFrame(new_columns)\n","    df1 = pd.concat([df_drop, new_df], axis=1)\n","\n","    del new_df\n","    gc.collect()\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeOSYw2tIBO0"},"outputs":[],"source":["def get_magnitude(df, num_features, df_drop):\n","    \"\"\" 振れ幅を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数名リスト\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get magnitude\", \"#\"*4)\n","    # 各列 ごとの magnitude を作成\n","    new_columns = {f'{col}_magnitude': df[f\"{col}_max\"] - df[f\"{col}_min\"] for col in tqdm(num_features)}\n","    new_df = pd.DataFrame(new_columns)\n","    df1 = pd.concat([df_drop, new_df], axis=1)\n","\n","    del new_df\n","    gc.collect()\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwbDa_oeIChh"},"outputs":[],"source":["def get_col_last_diff(df, num_features, df_drop):\n","    \"\"\" 最近の値との差分を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        num_features(list) : 数値型の変数名リスト\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get col_last diff\", \"#\"*4)\n","    # 各列 ごとの col_last_diff を作成\n","    new_columns = {f'{col}_lag_sub' : (df[col] - df[col.replace('last', col_2)]) for col in tqdm(num_features) for col_2 in ['first', 'mean', 'std', 'min', 'max'] if 'last' in col  and col.replace('last', col_2) in df}\n","    new_columns2 = {f'{col}_lag_div' : df[col] / df[col.replace('last', col_2)] for col in tqdm(num_features) for col_2 in ['first', 'mean', 'std', 'min', 'max'] if 'last' in col and col.replace('last', col_2) in df}\n","    new_columns.update(new_columns2)\n","    new_df = pd.DataFrame(new_columns)\n","    df1 = pd.concat([df_drop, new_df], axis=1)    \n","\n","    del new_df\n","    gc.collect()\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L8h9zrLFIDb0"},"outputs":[],"source":["def get_after_pay(df, df_drop):\n","    \"\"\" after_pay を追加する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get after pay\", \"#\"*4)\n","    # 各列 ごとの after_pay を作成\n","    new_columns = {f'{bcol}-{pcol}' : df[bcol] - df[pcol] for bcol in tqdm(['B_11','B_14','B_17','D_39','D_131','S_16','S_23']) for pcol in ['P_2','P_3'] if bcol in df.columns}\n","    new_df = pd.DataFrame(new_columns)\n","    df1 = pd.concat([df_drop, new_df], axis=1)    \n","    \n","    del new_df\n","    gc.collect()\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6lZApG3IEU8"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","def get_label(df, cat_features, df_drop):\n","    \"\"\" label encode する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        cat_features(list) : カテゴリ変数名\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\" \n","\n","    print(\"\\n\", \"#\"*4, \"get label\", \"#\"*4)\n","    # カテゴリ変数毎にラベルエンコーディング\n","    encoder = LabelEncoder()\n","    new_columns = {f\"{cat_col}_label\" : encoder.fit_transform(df[cat_col]) for cat_col in tqdm(cat_features)}\n","    new_df = pd.DataFrame(new_columns)\n","    df1 = pd.concat([df_drop, new_df], axis=1)    \n","    \n","    del new_df\n","    gc.collect()\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","        \n","    # 余分なメモリの削除\n","    df = reduce_mem_usage(df)\n","    gc.collect() \n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qns9M-bEIFQM"},"outputs":[],"source":["def get_frequency(df, cat_features, len_train, df_drop):\n","    \"\"\" frequency encode する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        cat_features(list) : カテゴリ変数名\n","        len_train(int) : データベースの行数\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","    \n","    print(\"\\n\", \"#\"*4, \"get frequency\", \"#\"*4)\n","    # カテゴリ変数毎にフリークエンシーエンコーディング\n","    new_columns = {f\"{cat_col}_freq\" : df[cat_col].map(dict(df[cat_col].value_counts())) / len_train for cat_col in tqdm(cat_features)}\n","    new_df = pd.DataFrame(new_columns)\n","    df1 = pd.concat([df_drop, new_df], axis=1)    \n","    \n","    del new_df\n","    gc.collect()\n","    \n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","        \n","    # 余分なメモリの削除\n","    df = reduce_mem_usage(df)\n","    gc.collect() \n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3m2VPDSRIGXQ"},"outputs":[],"source":["def mark_imputed(df, missing_cols, df_drop):\n","    \"\"\"欠損値の有無をメモ、欠損値を -1 で補完する関数\n","    \n","    Args:\n","        df(DataFrame) : データベース\n","        missing_cols(list) : 既存データベースのうち、欠損値がある変数名\n","\n","    Return:\n","        df(DataFrame) : 加工したデータベース\n","\n","    \"\"\"\n","\n","    print(\"\\n\", \"#\"*4, \"get imputation\", \"#\"*4)\n","    # 変数毎に欠損値をマーク\n","    new_columns = {f\"{col}__missing\" : df[col].isna() for col in tqdm(missing_cols)}\n","    new_df = pd.DataFrame(new_columns)\n","    df1 = pd.concat([df_drop, new_df], axis=1)    \n","    \n","    del new_df\n","    gc.collect()\n","\n","    # 既存のデータベースとマージ\n","    df = get_concat(df, df1)\n","    \n","    # 欠損値を -1 に補完\n","    for col in tqdm(df.columns.tolist()):\n","        df[col].fillna(-1)\n","        \n","    # 余分なメモリの削除\n","    df = reduce_mem_usage(df)\n","    gc.collect() \n","    \n","    return df"]},{"cell_type":"markdown","metadata":{"id":"SC_Grsv1IIXe"},"source":["# まとめ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1CVtYIwIHX-"},"outputs":[],"source":["def preprocess_all(train):\n","    \"\"\"用意した加工を行ってまとめる関数\n","    \n","    Args:\n","        train(DataFrame) : 既存のデータベース\n","\n","    Return:\n","        new_df(DataFrame) : 加工した変数が全て入ったデータベース\n","\n","    \"\"\"\n","    \n","    # 余分なメモリの削除\n","    new_df = reduce_mem_usage(train)\n","    \n","    # リストの作成\n","    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n","    cat_features = [\n","    \"B_30\",\n","    \"B_38\",\n","    \"D_114\",\n","    \"D_116\",\n","    \"D_117\",\n","    \"D_120\",\n","    \"D_126\",\n","    \"D_63\",\n","    \"D_64\",\n","    \"D_66\",\n","    \"D_68\",\n","    ]    \n","    num_features = [col for col in features if col not in cat_features]\n","    missing_cols = train.drop(['S_2'], axis = 1).isna().columns.to_list()\n","    len_train = len(train)\n","    \n","    # グループバイデータベースの作成\n","    groups = train.groupby(\"customer_ID\")\n","    \n","    # 空のデータベースの作成\n","    df_drop = train.drop(train.columns.tolist(), axis=1).copy()\n","\n","    # 不要なデータベースの削除\n","    del train\n","    gc.collect()\n","    \n","    # 関数の実行\n","    new_df = get_datetime(new_df)\n","    new_df = get_shift(new_df, num_features, groups)\n","    new_df = get_diff(new_df, num_features, groups)\n","    new_df = get_mean(new_df, num_features, groups)\n","    new_df = get_std(new_df, num_features, groups)\n","    new_df = get_median(new_df, num_features, groups)\n","    new_df = get_min(new_df, num_features, groups)\n","    new_df = get_max(new_df, num_features, groups)\n","    new_df = get_var(new_df, num_features, groups)\n","    new_df = get_first(new_df, features, groups)\n","    new_df = get_last(new_df, features, groups)\n","    new_df = get_count(new_df, cat_features, groups)\n","    new_df = get_nunique(new_df, cat_features, groups)\n","    new_df = get_current_level(new_df, num_features, df_drop)\n","    new_df = get_magnitude(new_df, num_features, df_drop)\n","    new_df = get_col_last_diff(new_df, num_features, df_drop)\n","    new_df = get_after_pay(new_df, df_drop)\n","    new_df = get_label(new_df, cat_features, df_drop)\n","    new_df = get_frequency(new_df, cat_features, len_train, df_drop)\n","    new_df = mark_imputed(new_df, missing_cols, df_drop)\n","    \n","    return new_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tx2Ho4oGILpu","outputId":"ae618ea5-7b8a-4402-9f05-c4eae48a65fe"},"outputs":[],"source":["new_train = preprocess_all(train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXt_CZHiINz5"},"outputs":[],"source":["new_test = preprocess_all(test)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPu3Tr1i9DtM0uKFlBlGR3q","collapsed_sections":["gmwzLHV_lcuf"],"machine_shape":"hm","mount_file_id":"1SMN0-gJQHTjJMc0-kSweJ4cTGRO5rb3q","name":"preprocess.ipynb","provenance":[{"file_id":"1SMN0-gJQHTjJMc0-kSweJ4cTGRO5rb3q","timestamp":1660091412108}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
